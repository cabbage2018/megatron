# 记录一次用于配电室的工业软网关的开发和分发及部署 #
主要论及稳定的开发出稳定的程序，这对工业生产环境还是比较重要的。

## 背景 ##
国内的产业环境还是处于集成为王的时代。这么的产业结构就使得物理层设备各品牌混杂 - 综保是进口的，断路器国产的，配电柜OEM 的，工人是本国的，通信集中器是定制和现场组态的。进货渠道千差万别，施工现场队伍复杂，销售故事讳莫如深，甲方根本见不到，但是验收又是实实在在的。如果有一天读者有幸接触这类项目他/她可能想自己开发一种软网关来采集现场组态后的电力数据，主要是二次设备的保护遥信，局放，弧光和测温等传感器的实时状态或者事件。一种比较稳定的通信协议目前看是OPC UA，所谓开放工业互联统一架构。可以想象这个行业有多么的亟需统一。开发环境你可能会选择Node.js 这样的跨平台的基于虚拟机编译的标准；另外一个，真的很重要的是，还是跨平台，真正我们开发过的跨平台产品可能一辈子也不会碰到，因为项目揍是定制的，不存在什么我今天写了一个程序大家用了都说好于是客户鼓励我们移植到什么macos 网关上那都是小说里的情节。实际案例是，你写了一个工业网关，于是大家说好！接下来就再没有任何人用。over。当然，现实也不一定这么糟，有可能是你写了一个Linux 的版本，但是等你远程登陆到向日葵上一看对方给你的是Windows Server 2007 而且十有八九是破解版的。或者跟你说没有激活所以不能上外网。这些都是有可能的，于是作为预防性架构的一部分，我们搞了一个win/macos/linux 3位一体程序，打包时就不会落地成盒的悲惨境地。C 语言有cmake 但是研究起来也不亚于makefile 似的博大精深； Java 是好jvm 保证了二进制多平台字节码统一了，可是那开发环境一装就要装半天，框架多到数不过来，这不是在开发应用而是被利用；vba 也是好，但是俺不会。于是数来数去就会JavaScript，于是就选择学习Node 环境。
### Node.js 环境的版本选择 ###
经过实践发现我依赖的模块在Node.js --version = 8 上跑的动，加之从前有个嵌入式项目锁定的版本就是8（那个项目换个10 的就装不到目标机上，编译node 二进制工程提示缺少某个C 库）暂定该版本就是目标版本，当然你本地开发可以用10 或者12 ， 只要打包时限定引擎的版本即可；于是牵扯到另外一个重大的琐事： 打包工具的调研。
### pkg ###
通过搜索发现这个工具还有人用，于是我也用它。事实证明有人回答编译错误真的很重要。这个过程中一个棘手的错误就是github 上牛人的答案救了我。整体而言，确实可以用，除去不多不少的几个坑，以及版本。这个工具是事后记录的，而开发当初项目需要在现场硬件故障时程序能发邮件告警，这个能力还是蛮吸引人的。所以当时选择的是邮件发送能力和， 它的上级，日志功能。
### 日志组件 ###
选择的是生态还不错的log4js。在它里面可以导出日志内容到多个appender， 例如基于nodemailer 的smtp。 就是说，log4js 用引用代码的方式引入了某个版本的nodemailer， 借此组件来发送smtp 邮件。邮件的configure 是可以讨论讨论的，反正只要能发送成功就是好组件。好在花了一晚上就基本上放弃了。。。不，基本上搞定了。这点要看你的邮箱服务供应商设置的方法是不是坑爹。免费的东西，能用就感谢上帝了。话说你开发实际项目时还是不要用免费邮箱来搞了，还是付费的高效。
## 代码及其管理 ##
现如今代码最不值钱了，维护和运营才是大佬们玩的玩意。但是也总要人开发，于是召唤了几个开源组件，基本有了这么一个区区上百行自己写的部分加上几十万行别人写的module 的一个组合。这个组合能够完成网关的基本功能： 协议数据采集。利用cron 组件的定时触发能力，唤醒一段数采程序，这个程序利用Promise 机制约定了采集成功的数据的返回结构，并传输到某个我们采购的云上虚机的MQTTs topic，导入Kafka 队列。node-opcua 的sample 程序网上有许多，但是对于这种依赖外部硬件响应的代码而言都有一个越不过去的坎就是对于sync 和async 的处理，照理说有用的程序都是sync 的，没有数据你更新啥？ 就像网站购物价格如果没有给你取回来你购啥物，RESTful API 调用token 没取到通啥信呢，现代的架构非得按照人的阅读习惯搞出一堆async 的语法并美其名曰可读性，在我看来就是鸡同鸭讲，浪费开发人员的大好时间去理解人为的障碍设置规则。案例们既都是sync 的await 某个返回值这种格式，而Node 又是非阻塞的async 本质，于是我利用了一个Promise 这种写法把sync的函数调用放到Promise 代码去用.then(callback).catch(callback) 去等待取到现场综保数据后publish 到topic 上。
数据的处理就是首先要理解协议，或者说module 定义，再加上放到现场环境去跑一跑，就能发现和解决70% 的问题。例如，可能你看了3000页的OPC UA 规范但还是不知道返回的数据格式，于是下面这段可能是你亟需获得的字符串

```
,{ /* DataValue */
   value: Variant(Scalar<Null>, value: <null>)
   statusCode:      BadNodeIdUnknown (0x80340000)
   serverTimestamp: null
   sourceTimestamp: null
},
```
不对，这是项目开始时错误的地址返回值； 正确的是这样的：

```
{ /* DataValue */
   value: Variant(Scalar<Double>, value: 0)
   statusCode:      Good (0x00000)
   serverTimestamp: null
   sourceTimestamp: null
}
```
这是特定的server 返回的内容，你的server 返回的如有雷同纯属巧合，不要以为有规范各家实现都会一样，每家基于规范都有自己的创造性实现，这里这台服务器没有填补serverTimestamp 和 sourceTimestamp 这原本用来计算传输时延和吞吐量很有用的时间戳就空白了；顺便说一句，工业环境还是别去学习用WIFI 取代wired LAN 了，这里面的时延不是一个数量级的，除非你具备TSN这样的昂贵版本的无线- 那为什么供应商不拉根线要知道在mainland客户眼里硬件才是唯一值钱的 人工和软件都是不需要存在的，管你神马玩意都要算固资才是正道。好歹value.value 跟你带出来了。最有意思的是运气好的话你看到这样类似的返回值

```
{ /* DataValue */
   value: Variant(Scalar<Double>, value: 0)
   statusCode:      BadWaitingForInitialData (0x80320000)
   serverTimestamp: null
   sourceTimestamp: null
}
```
关注点是quality code 的说明；如果说
```
   statusCode:      BadNodeIdUnknown (0x80340000)
```
得到这样的返回值是告诉你服务器上也许没有这个node Id，因为你拿到手的文件可能有typo。抑或服务器配置时抖了一下手就改了名字；前面的一则状态码 说明传感器数据还没到通信集中器（MODBUS/TCP）需要检查硬件尤其是南向部分的。

### 论代码用git branch 管理的缺点 ###
为了验证最终代码的正确性我先找了一台别的公司的server 验证了一下，于是，我的代码裂成了2 部分，一个是适配验证server 的简化版另外一个是开发了3个晚上的正式发行版。以我的浅薄的理解来说这个世界上估计除了我没有第二个人能够理解高度定制化的硬件造型和正交不变下的数据扭曲旋转也就是说全球没有第二个人能够给我的代码提出任何意见，我可以放心的利用git 的branch 功能来管理我寥寥无几的几行代码- 燃鹅它们都是无价之宝。因为一旦丢失我的项目就没法进行了，销售会把我们都干掉。这里面的核心就在于扭曲。某一天当你对于管理多个repo 感到厌烦和无聊的时候你可以用
```
git checkout -b opcua_feature_1
```
创建一个本地的代码分支并在上开发特定功能并测试和提交，一旦完成就切换回主分支例如master。 而在feature 分支上完成的价值点例如配置，格式，逻辑，流程可以merge 到主分支来，对于交付来说只需要关注主分支即可，其它的一切都是验证和测试，而且留有案底，万一哪天硬件平台切换了我们还可以回退到验证环境重新跑一下模块测试。从别人那里得知，提交本地分支到远程是以下这样的方法：
```
git push origin local_branch:remote_branch
```
local_branch 和 remote_branch 名字可以一样，不过它们存储的位置不一样而已。git branch -a 很容易看到所有分支状况； git branch -r 查看远程分支状况。
利用分支进行代码管理的缺点，呃，就是太方便，太惫懒了。
### 性能 ###
性能的瓶颈主要依赖测试技术和客户要求来调整。很繁琐。建议不要尝试调优，弄得遍地bug 怨天尤人 还影响团队的团结和凝聚力。调优迟早散伙。鄙人哲学是能用就用，不能用就放弃。无为而治。
### 打包via pkg ###
当你安装好了pkg 工具后，如果你是在windows 平台搞的开发，记住上这个帖子里找到补丁方法以治愈pkg ./package.json 时的[Applying Patches Error: spawn patch ENOENT](https://github.com/vercel/pkg/issues/236) 能够节约你好几个小时的时间。打包网站类型的项目（我倾向于利用Express + ejs 搭建网站形式来发布网关程序因为在局域网可以访问必要的信息例如日志记录和报表）你会遇到public及views 目录下的文件(.css 以及 .ejs 模板等) 无法在runtime 时被找到的情况，需要在pkg 的配置里(package.json)专门指明
```
  "bin": "bin/www",
  "pkg": {
    "assets": [
      "public/**/*",
      "views/**"
    ],
    "targets": [
      "node8-windows-x64"
    ],
    "outputPath": "pkg/"
  },

```
在app.js 所在目录下运行'pkg -t win ./package.json' 等上几分钟你就能得到一个可以运行在windows 平台的.exe 文件。神奇的事情是目标机器无需安装Node 环境。虽然我没有成功在win 平台编译出linux和 macos 的二进制分发包，但是也已经足够了，因为能随意指定target Node 的版本例如10， 12， 14等，这点值得称赞。地道。
另外，程序运行时如果需要加载配置文件，这个文件在代码里要用形如'JSON.parse(fs.readFileSync(path.join(process.cwd(), './config/log4js_options.json')))' 这种运行时动态加载方式读入代码里；其次运行时你得真的把这个options文件放到config 目录下！ 否则程序就崩溃了。因为这里采用 process.cwd() 这样的运行时变量而非 __dirname 这样的编译器静态变量，所以动态配置不成问题。log 文件也可以做成动态放置到某个目录，或者直接发往某个邮箱。

### 发送邮件 ###
nodemailer 发送邮件需要提供smtp服务器和它的鉴权也就是用户名和使能码。

### 处理巨量的数据点位log ###
数据采集不可怕，怕的是巨量数据把目标机硬盘撑爆而远程的我无法感应。如果把OPC UA 处理的response 打印到log 每分钟采集10k 点位一个小时你就能轻而易举创造出100MB 的日志文件，大部分生产环境不需要如此高密度日志。于是我想到一个办法，在采集当中建立一个字典，键值就是点位的地址nodeId例如ns=2054;i=10093; 每次数据更新在Map() 里set(nodeId, value + timestamp) 这样如果把字典用网页来展现就使读者非常清楚的看到每个点位最后一次更新的时间以及最新值是几何。非常容易定位硬件以及连接故障。

```
router.get('/acq', function(req, res, next) {
  let bridge = require('./bridge')
  let dict = bridge.profilingDictionary
  res.render('dictionary', {
    title: __filename + new Date().toISOString(),
    items: dict
  })
})

module.exports = router
```

这就是为什么ejs 和express 备受青睐。它把定位故障的透明直接简化到浏览器的水准。核验数据的同时不影响采集的进行。这才是真正利用了Node 的异步性的地方。所以占用128M 内存也就不算什么了。毕竟真正的网关还是要能显示最新报表。

## 未完成的任务 ##
exe 需要长期无人值守运行，重启后自动启动，不需要有console界面否则容易被别人暂停 - 这样的任务最好在windows 里做成service 也就是服务。sc create 很容易就创建它，但是很遗憾我启动不了这个exe 程序，也许是3000 端口已经被占用，也许是搜索结果里说的net service 加入管理员组提升权限（？），也许是程序timeout 阻挠了服务的启动，总而言之这步失败了。我在想是不是可以把PM2 这样的代码管控工具一并用pkg 打包呢？ 如果这条路不通，那我可能需要把网站部分剥离出来做成一个纯粹的无界面不依赖 web service 的内核，仅仅通过tcp IO传递必须的信息。难不成最终还是要做成一个daemon 精灵程序？